{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd \n",
    "#import modin.pandas as pd\n",
    "from tqdm import tqdm\n",
    "import datetime\n",
    "from p_tqdm import p_map\n",
    "from functools import partial\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_resolution = '1'\n",
    "lk_path = '/mnt/data0/lkyin/'\n",
    "c_path = './network_data'+str(time_resolution)+'/commits/'\n",
    "e_path = './network_data'+str(time_resolution)+'/emails/'\n",
    "mix_path = './network_data'+str(time_resolution)+'/mix/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing commits data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4312196"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data = df_data.loc[df_data.date.str.len()==19]\n",
    "len(df_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data['datetime'] = df_data['date'].apply(lambda x: pd.Period(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Series.describe of 0          2009-01-12 17:11:30\n",
       "1          2009-01-12 17:11:30\n",
       "2          2009-01-12 17:11:30\n",
       "3          2009-01-12 17:11:30\n",
       "4          2009-01-12 17:11:30\n",
       "                  ...         \n",
       "4312472    2013-01-25 12:55:09\n",
       "4312473    2013-01-25 12:55:10\n",
       "4312474    2013-01-25 12:55:10\n",
       "4312475    2013-01-25 12:55:10\n",
       "4312476    2013-01-25 12:55:10\n",
       "Name: datetime, Length: 4312196, dtype: period[S]>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data['datetime'].describe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data['year'] = df_data['datetime'].apply(lambda x: x.year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data['dayofyear'] = df_data['datetime'].apply(lambda x: x.dayofyear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data['weekofyear'] = df_data['datetime'].apply(lambda x: x.weekofyear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data['week'] = df_data['datetime'].apply(lambda x: pd.Period(x, freq='W'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count                   4312196\n",
       "unique                      834\n",
       "top       2011-05-30/2011-06-05\n",
       "freq                      69047\n",
       "Name: week, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data['week'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "107"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(weekly_df_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading commits...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: Ray execution environment not yet initialized. Initializing...\n",
      "To remove this warning, run the following python code before doing dataframe operations:\n",
      "\n",
      "    import ray\n",
      "    ray.init()\n",
      "\n",
      "UserWarning: The size of /dev/shm is too small (21517848576 bytes). The required size at least half of RAM (33617885184 bytes). Please, delete files in /dev/shm or increase size of /dev/shm with --shm-size in Docker. Also, you can set the required memory size for each Ray worker in bytes to MODIN_MEMORY environment variable.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grouping by project...\n",
      "grouping by period...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 5/263 [01:18<1:03:00, 14.65s/it]2021-11-29 11:23:39,248\tWARNING import_thread.py:123 -- The actor '_QueueActor' has been exported 100 times. It's possible that this warning is accidental, but this may indicate that the same remote function is being defined repeatedly from within many tasks and exported to all of the workers. This can be a performance issue and can be resolved by defining the remote function on the driver instead. See https://github.com/ray-project/ray/issues/6240 for more discussion.\n",
      " 14%|█▍        | 37/263 [07:45<29:46,  7.90s/it]2021-11-29 11:30:26,597\tWARNING worker.py:1228 -- The actor or task with ID c771d6d9f8728163e9bbfdd6aefae4cd53994d5fd544eb3b cannot be scheduled right now. You can ignore this message if this Ray cluster is expected to auto-scale or if you specified a runtime_env for this actor or task, which may take time to install.  Otherwise, this is likely due to all cluster resources being claimed by actors. To resolve the issue, consider creating fewer actors or increasing the resources available to this Ray cluster.\n",
      "Required resources for this actor or task: {CPU: 1.000000}\n",
      "Available resources on this node: {11.000000/12.000000 CPU, 585937500.000000 GiB/585937500.000000 GiB memory, 1.000000/1.000000 GPU, 585937500.000000 GiB/585937500.000000 GiB object_store_memory, 1.000000/1.000000 accelerator_type:V, 1.000000/1.000000 node:169.237.4.64}\n",
      "In total there are 1 pending tasks and 0 pending actors on this node.\n",
      " 19%|█▉        | 50/263 [10:13<17:09,  4.83s/it]2021-11-29 11:32:26,748\tWARNING worker.py:1228 -- The actor or task with ID 9224ebcf8a950f97aa4fe74ecda1c1c65e5caca993013cb3 cannot be scheduled right now. You can ignore this message if this Ray cluster is expected to auto-scale or if you specified a runtime_env for this actor or task, which may take time to install.  Otherwise, this is likely due to all cluster resources being claimed by actors. To resolve the issue, consider creating fewer actors or increasing the resources available to this Ray cluster.\n",
      "Required resources for this actor or task: {CPU: 1.000000}\n",
      "Available resources on this node: {11.000000/12.000000 CPU, 585937500.000000 GiB/585937500.000000 GiB memory, 1.000000/1.000000 GPU, 585937500.000000 GiB/585937500.000000 GiB object_store_memory, 1.000000/1.000000 accelerator_type:V, 1.000000/1.000000 node:169.237.4.64}\n",
      "In total there are 1 pending tasks and 0 pending actors on this node.\n",
      " 24%|██▍       | 63/263 [13:20<52:08, 15.64s/it]2021-11-29 11:35:36,979\tWARNING worker.py:1228 -- The actor or task with ID 0e41af20e78ad7415107fd1779d2556fc55b1bc881b2c577 cannot be scheduled right now. You can ignore this message if this Ray cluster is expected to auto-scale or if you specified a runtime_env for this actor or task, which may take time to install.  Otherwise, this is likely due to all cluster resources being claimed by actors. To resolve the issue, consider creating fewer actors or increasing the resources available to this Ray cluster.\n",
      "Required resources for this actor or task: {CPU: 1.000000}\n",
      "Available resources on this node: {11.000000/12.000000 CPU, 585937500.000000 GiB/585937500.000000 GiB memory, 1.000000/1.000000 GPU, 585937500.000000 GiB/585937500.000000 GiB object_store_memory, 1.000000/1.000000 accelerator_type:V, 1.000000/1.000000 node:169.237.4.64}\n",
      "In total there are 1 pending tasks and 0 pending actors on this node.\n",
      " 25%|██▌       | 67/263 [13:58<42:11, 12.91s/it]2021-11-29 11:36:27,018\tWARNING worker.py:1228 -- The actor or task with ID 220e6f61ca36582b13587baa0ea849778ed1f3c31cddb2cb cannot be scheduled right now. You can ignore this message if this Ray cluster is expected to auto-scale or if you specified a runtime_env for this actor or task, which may take time to install.  Otherwise, this is likely due to all cluster resources being claimed by actors. To resolve the issue, consider creating fewer actors or increasing the resources available to this Ray cluster.\n",
      "Required resources for this actor or task: {CPU: 1.000000}\n",
      "Available resources on this node: {11.000000/12.000000 CPU, 585937500.000000 GiB/585937500.000000 GiB memory, 1.000000/1.000000 GPU, 585937500.000000 GiB/585937500.000000 GiB object_store_memory, 1.000000/1.000000 accelerator_type:V, 1.000000/1.000000 node:169.237.4.64}\n",
      "In total there are 1 pending tasks and 0 pending actors on this node.\n",
      " 28%|██▊       | 74/263 [16:36<1:14:00, 23.50s/it]2021-11-29 11:38:57,255\tWARNING worker.py:1228 -- The actor or task with ID 3a4481f2a4605112b3c732f1e2309de5aa0fb92a461d9a25 cannot be scheduled right now. You can ignore this message if this Ray cluster is expected to auto-scale or if you specified a runtime_env for this actor or task, which may take time to install.  Otherwise, this is likely due to all cluster resources being claimed by actors. To resolve the issue, consider creating fewer actors or increasing the resources available to this Ray cluster.\n",
      "Required resources for this actor or task: {CPU: 1.000000}\n",
      "Available resources on this node: {11.000000/12.000000 CPU, 585937500.000000 GiB/585937500.000000 GiB memory, 1.000000/1.000000 GPU, 585937500.000000 GiB/585937500.000000 GiB object_store_memory, 1.000000/1.000000 accelerator_type:V, 1.000000/1.000000 node:169.237.4.64}\n",
      "In total there are 1 pending tasks and 0 pending actors on this node.\n",
      " 29%|██▊       | 75/263 [16:55<1:09:52, 22.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(apply_list_of_funcs pid=15302)\u001b[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 77/263 [17:40<1:07:37, 21.81s/it]2021-11-29 11:40:07,389\tWARNING worker.py:1228 -- The actor or task with ID 73c43c7afe45b4357271e94be83b8a4cc2462df943bcc176 cannot be scheduled right now. You can ignore this message if this Ray cluster is expected to auto-scale or if you specified a runtime_env for this actor or task, which may take time to install.  Otherwise, this is likely due to all cluster resources being claimed by actors. To resolve the issue, consider creating fewer actors or increasing the resources available to this Ray cluster.\n",
      "Required resources for this actor or task: {CPU: 1.000000}\n",
      "Available resources on this node: {11.000000/12.000000 CPU, 585937500.000000 GiB/585937500.000000 GiB memory, 1.000000/1.000000 GPU, 585937500.000000 GiB/585937500.000000 GiB object_store_memory, 1.000000/1.000000 accelerator_type:V, 1.000000/1.000000 node:169.237.4.64}\n",
      "In total there are 1 pending tasks and 0 pending actors on this node.\n",
      " 42%|████▏     | 110/263 [24:35<27:13, 10.67s/it]2021-11-29 11:47:07,808\tWARNING worker.py:1228 -- The actor or task with ID 5c79006a477a2a8b035c717c41754cb6b6e4ec47d73bb056 cannot be scheduled right now. You can ignore this message if this Ray cluster is expected to auto-scale or if you specified a runtime_env for this actor or task, which may take time to install.  Otherwise, this is likely due to all cluster resources being claimed by actors. To resolve the issue, consider creating fewer actors or increasing the resources available to this Ray cluster.\n",
      "Required resources for this actor or task: {CPU: 1.000000}\n",
      "Available resources on this node: {11.000000/12.000000 CPU, 585937500.000000 GiB/585937500.000000 GiB memory, 1.000000/1.000000 GPU, 585937500.000000 GiB/585937500.000000 GiB object_store_memory, 1.000000/1.000000 accelerator_type:V, 1.000000/1.000000 node:169.237.4.64}\n",
      "In total there are 1 pending tasks and 0 pending actors on this node.\n",
      " 52%|█████▏    | 137/263 [30:29<28:09, 13.41s/it]2021-11-29 11:52:58,396\tWARNING worker.py:1228 -- The actor or task with ID eeb7aca6ac77a10a80b7d3044bffcc334aed05b5eed77edc cannot be scheduled right now. You can ignore this message if this Ray cluster is expected to auto-scale or if you specified a runtime_env for this actor or task, which may take time to install.  Otherwise, this is likely due to all cluster resources being claimed by actors. To resolve the issue, consider creating fewer actors or increasing the resources available to this Ray cluster.\n",
      "Required resources for this actor or task: {CPU: 1.000000}\n",
      "Available resources on this node: {11.000000/12.000000 CPU, 585937500.000000 GiB/585937500.000000 GiB memory, 1.000000/1.000000 GPU, 585937500.000000 GiB/585937500.000000 GiB object_store_memory, 1.000000/1.000000 accelerator_type:V, 1.000000/1.000000 node:169.237.4.64}\n",
      "In total there are 1 pending tasks and 0 pending actors on this node.\n",
      " 65%|██████▌   | 172/263 [38:26<18:39, 12.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(apply_list_of_funcs pid=25028)\u001b[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 179/263 [40:34<26:20, 18.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(apply_list_of_funcs pid=31604)\u001b[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 186/263 [41:31<12:02,  9.39s/it]2021-11-29 12:03:48,970\tWARNING worker.py:1228 -- The actor or task with ID 4c2889ccc47a5e335bfbdd1e05f7660da343d32500e391d7 cannot be scheduled right now. You can ignore this message if this Ray cluster is expected to auto-scale or if you specified a runtime_env for this actor or task, which may take time to install.  Otherwise, this is likely due to all cluster resources being claimed by actors. To resolve the issue, consider creating fewer actors or increasing the resources available to this Ray cluster.\n",
      "Required resources for this actor or task: {CPU: 1.000000}\n",
      "Available resources on this node: {11.000000/12.000000 CPU, 585937500.000000 GiB/585937500.000000 GiB memory, 1.000000/1.000000 GPU, 585937500.000000 GiB/585937500.000000 GiB object_store_memory, 1.000000/1.000000 accelerator_type:V, 1.000000/1.000000 node:169.237.4.64}\n",
      "In total there are 1 pending tasks and 0 pending actors on this node.\n",
      " 74%|███████▍  | 194/263 [43:30<12:42, 11.05s/it]2021-11-29 12:05:59,028\tWARNING worker.py:1228 -- The actor or task with ID 990dad0e38a0cc095b25ad7387d9df2b28c5e0aced850815 cannot be scheduled right now. You can ignore this message if this Ray cluster is expected to auto-scale or if you specified a runtime_env for this actor or task, which may take time to install.  Otherwise, this is likely due to all cluster resources being claimed by actors. To resolve the issue, consider creating fewer actors or increasing the resources available to this Ray cluster.\n",
      "Required resources for this actor or task: {CPU: 1.000000}\n",
      "Available resources on this node: {11.000000/12.000000 CPU, 585937500.000000 GiB/585937500.000000 GiB memory, 1.000000/1.000000 GPU, 585937500.000000 GiB/585937500.000000 GiB object_store_memory, 1.000000/1.000000 accelerator_type:V, 1.000000/1.000000 node:169.237.4.64}\n",
      "In total there are 1 pending tasks and 0 pending actors on this node.\n",
      " 76%|███████▌  | 200/263 [45:03<13:14, 12.60s/it]2021-11-29 12:07:19,070\tWARNING worker.py:1228 -- The actor or task with ID ae823ac1614198c8392168297fe2a13aa1b6ea9f6167cfd3 cannot be scheduled right now. You can ignore this message if this Ray cluster is expected to auto-scale or if you specified a runtime_env for this actor or task, which may take time to install.  Otherwise, this is likely due to all cluster resources being claimed by actors. To resolve the issue, consider creating fewer actors or increasing the resources available to this Ray cluster.\n",
      "Required resources for this actor or task: {CPU: 1.000000}\n",
      "Available resources on this node: {11.000000/12.000000 CPU, 585937500.000000 GiB/585937500.000000 GiB memory, 1.000000/1.000000 GPU, 585937500.000000 GiB/585937500.000000 GiB object_store_memory, 1.000000/1.000000 accelerator_type:V, 1.000000/1.000000 node:169.237.4.64}\n",
      "In total there are 1 pending tasks and 0 pending actors on this node.\n",
      " 89%|████████▉ | 235/263 [55:11<09:19, 19.98s/it]2021-11-29 12:17:29,528\tWARNING worker.py:1228 -- The actor or task with ID 626679152043495f3efac4afc255f5dcc71c7bf89dfb8e2d cannot be scheduled right now. You can ignore this message if this Ray cluster is expected to auto-scale or if you specified a runtime_env for this actor or task, which may take time to install.  Otherwise, this is likely due to all cluster resources being claimed by actors. To resolve the issue, consider creating fewer actors or increasing the resources available to this Ray cluster.\n",
      "Required resources for this actor or task: {CPU: 1.000000}\n",
      "Available resources on this node: {11.000000/12.000000 CPU, 585937500.000000 GiB/585937500.000000 GiB memory, 1.000000/1.000000 GPU, 585937500.000000 GiB/585937500.000000 GiB object_store_memory, 1.000000/1.000000 accelerator_type:V, 1.000000/1.000000 node:169.237.4.64}\n",
      "In total there are 1 pending tasks and 0 pending actors on this node.\n",
      " 96%|█████████▌| 252/263 [1:00:22<03:41, 20.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(apply_list_of_funcs pid=846)\u001b[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 263/263 [1:03:23<00:00, 14.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Commits Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ------------------- processing commits ---------------------- \n",
    "print('reading commits...')\n",
    "df = pd.read_csv(lk_path+'commits_final.csv')\n",
    "print('grouping by project...')\n",
    "df = dict(tuple(df.groupby(df['project_name'])))\n",
    "to_path = './monthly_data/commits/'\n",
    "if not os.path.exists(to_path):\n",
    "\tos.makedirs(to_path)\n",
    "\n",
    "print('grouping by period...')\n",
    "for project in tqdm(df):\n",
    "\tmonthly_df_dict = dict(tuple(df[project].groupby(df[project]['month'])))\n",
    "\tmonthint = 0\n",
    "\tfor month in monthly_df_dict:\n",
    "\t\tmonthly_df = monthly_df_dict[month]\n",
    "\t\tmonthly_df = monthly_df[monthly_df['dealised_author_full_name'].notna()]\n",
    "\t\tmonthint+=1\n",
    "\t\tif monthly_df.empty: continue\n",
    "\t\tfile_path = to_path + '{}__{}.csv'.format(project, str(monthint))\n",
    "\t\tmonthly_df.to_csv(file_path, index=False)\n",
    "print('Commits Done.')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading emails...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/orzwang/.pyenv/versions/3.8.10/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3444: DtypeWarning: Columns (9,13) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grouping by project...\n",
      "grouping by period...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 275/275 [03:58<00:00,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emails Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ------------------- processing emails ---------------------- \n",
    "print('reading emails...')\n",
    "df = pd.read_csv(lk_path+'emails_final.csv')\n",
    "print('grouping by project...')\n",
    "df = dict(tuple(df.groupby(df['project_name'])))\n",
    "to_path = './monthly_data/emails/'\n",
    "if not os.path.exists(to_path):\n",
    "\tos.makedirs(to_path)\n",
    "\n",
    "print('grouping by period...')\n",
    "for project in tqdm(df):\n",
    "\tmonthly_df_dict = dict(tuple(df[project].groupby(df[project]['month'])))\n",
    "\tmonthint = 0\n",
    "\tfor month in monthly_df_dict:\n",
    "\t\tmonthly_df = monthly_df_dict[month]\n",
    "\t\tmonthly_df = monthly_df[monthly_df['dealised_author_full_name'].notna()]\n",
    "\t\tmonthint+=1\n",
    "\t\tif monthly_df.empty: continue\n",
    "\t\tfile_path = to_path + '{}__{}.csv'.format(project, str(monthint))\n",
    "\t\tmonthly_df.to_csv(file_path, index=False)\n",
    "print('Emails Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0c125d54415bf97f751e5832101874a2f084e84c850663dda323e1a70b27f8b7"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('3.8.10': pyenv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
