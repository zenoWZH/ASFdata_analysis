{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd \n",
    "#import modin.pandas as pd # emails went to 236\n",
    "from tqdm import tqdm\n",
    "import datetime\n",
    "from p_tqdm import p_map\n",
    "from functools import partial\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_resolution = '1week'\n",
    "lk_path = '/mnt/data0/lkyin/'\n",
    "c_path = './network_data'+str(time_resolution)+'/commits/'\n",
    "e_path = './network_data'+str(time_resolution)+'/emails/'\n",
    "mix_path = './network_data'+str(time_resolution)+'/mix/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing commits data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading commits...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: Ray execution environment not yet initialized. Initializing...\n",
      "To remove this warning, run the following python code before doing dataframe operations:\n",
      "\n",
      "    import ray\n",
      "    ray.init()\n",
      "\n",
      "UserWarning: The size of /dev/shm is too small (31606259712 bytes). The required size at least half of RAM (33617885184 bytes). Please, delete files in /dev/shm or increase size of /dev/shm with --shm-size in Docker. Also, you can set the required memory size for each Ray worker in bytes to MODIN_MEMORY environment variable.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grouping by project...\n"
     ]
    }
   ],
   "source": [
    "print('reading commits...')\n",
    "df_data = pd.read_csv(lk_path+'commits_final.csv')\n",
    "print('grouping by project...')\n",
    "df = dict(tuple(df_data.groupby(df_data['project_name'])))\n",
    "to_path = './weekly_data/commits/'\n",
    "if not os.path.exists(to_path):\n",
    "\tos.makedirs(to_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['abdera', 'accumulo', 'ace', 'activemq', 'adffaces', 'agila', 'airavata', 'airflow', 'allura', 'alois', 'amaterasu', 'ambari', 'ant', 'any23', 'apex', 'apisix', 'ariatosca', 'aries', 'asterixdb', 'atlas', 'aurora', 'awf', 'batchee', 'beam', 'beehive', 'bigtop', 'bloodhound', 'bluesky', 'blur', 'bookkeeper', 'brooklyn', 'buildr', 'bval', 'calcite', 'carbondata', 'cassandra', 'cayenne', 'celix', 'chemistry', 'chukwa', 'clerezza', 'click', 'climate', 'cloudstack', 'cmda', 'commons', 'commonsrdf', 'composer', 'concerted', 'cordova', 'corinthia', 'couchdb', 'crunch', 'ctakes', 'curator', 'cxf', 'daffodil', 'datafu', 'datasketches', 'deltacloud', 'deltaspike', 'derby', 'devicemap', 'directmemory', 'directory', 'dolphinscheduler', 'drill', 'droids', 'druid', 'dubbo', 'eagle', 'echarts', 'edgent', 'empire', 'esme', 'etch', 'falcon', 'felix', 'fineract', 'flex', 'flink', 'flume', 'fluo', 'freemarker', 'ftpserver', 'gearpump', 'geode', 'giraph', 'gobblin', 'gora', 'gossip', 'graffito', 'griffin', 'groovy', 'guacamole', 'hama', 'harmony', 'hawq', 'hcatalog', 'hdt', 'helix', 'heraldry', 'hise', 'horn', 'htrace', 'hudi', 'ibatis', 'iceberg', 'ignite', 'impala', 'imperius', 'iota', 'iotdb', 'isis', 'ivy', 'jackrabbit', 'jclouds', 'jdo', 'jena', 'johnzon', 'joshua', 'jspwiki', 'juice', 'juneau', 'kabuki', 'kafka', 'kalumet', 'kato', 'kitty', 'knox', 'kudu', 'kylin', 'lens', 'libcloud', 'lokahi', 'lucenenet', 'lucy', 'madlib', 'manifoldcf', 'mesos', 'metamodel', 'metron', 'mnemonic', 'mod_ftp', 'mrql', 'mrunit', 'muse', 'myfaces', 'mynewt', 'myriad', 'netbeans', 'nifi', 'nmaven', 'npanday', 'nutch', 'nuvem', 'ode', 'odf', 'ofbiz', 'olingo', 'olio', 'oltu', 'omid', 'onami', 'oodt', 'oozie', 'openaz', 'openjpa', 'openmeetings', 'opennlp', 'openoffice', 'openwebbeans', 'openwhisk', 'parquet', 'pdfbox', 'phoenix', 'photark', 'pig', 'pinot', 'pirk', 'pivot', 'plc4x', 'predictionio', 'provisionr', 'pubscribe', 'pulsar', 'qpid', 'quickstep', 'ranger', 'ratis', 'rave', 'rcf', 'reef', 'ripple', 'river', 'rocketmq', 'roller', 'rya', 's2graph', 's4', 'samoa', 'samza', 'sanselan', 'sentry', 'servicecomb', 'servicemix', 'shardingsphere', 'shindig', 'shiro', 'singa', 'sirona', 'sis', 'skywalking', 'slider', 'sling', 'solr', 'spark', 'sqoop', 'stanbol', 'stdcxx', 'stonehenge', 'storm', 'stratos', 'streams', 'struts', 'subversion', 'superset', 'synapse', 'syncope', 'systemml', 'tajo', 'tamaya', 'tashi', 'taverna', 'tephra', 'tez', 'thrift', 'tika', 'tinkerpop', 'trafficcontrol', 'trafficserver', 'trafodion', 'triplesoup', 'tuscany', 'tvm', 'twill', 'uima', 'unomi', 'usergrid', 'vcl', 'vxquery', 'warble', 'wave', 'weex', 'whirr', 'wicket', 'wink', 'wookie', 'xap', 'yoko', 'zeppelin', 'zeta', 'zipkin'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['project_name', 'list_name', 'date', 'month', 'message_id',\n",
       "       'sender_name', 'sender_email', 'author_name', 'author_email',\n",
       "       'file_name', 'loc', 'ref_or_sha', 'subject', 'commit_type',\n",
       "       'incubation_time', 'author_full_name', 'is_bot', 'is_coding',\n",
       "       'dealised_author_full_name'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2009-01-12 17:11:30</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2009-01-12 17:11:30</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2009-01-12 17:11:30</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2009-01-12 17:11:30</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2009-01-12 17:11:30</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2009-01-12 17:11:30</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2009-01-12 17:11:30</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2009-01-12 17:11:30</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2009-01-12 17:11:30</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2009-01-12 17:11:30</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  date  month\n",
       "0  2009-01-12 17:11:30      4\n",
       "1  2009-01-12 17:11:30      4\n",
       "2  2009-01-12 17:11:30      4\n",
       "3  2009-01-12 17:11:30      4\n",
       "4  2009-01-12 17:11:30      4\n",
       "5  2009-01-12 17:11:30      4\n",
       "6  2009-01-12 17:11:30      4\n",
       "7  2009-01-12 17:11:30      4\n",
       "8  2009-01-12 17:11:30      4\n",
       "9  2009-01-12 17:11:30      4"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data[['date','month']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Series.describe of 0          2009-01-12 17:11:30\n",
       "1          2009-01-12 17:11:30\n",
       "2          2009-01-12 17:11:30\n",
       "3          2009-01-12 17:11:30\n",
       "4          2009-01-12 17:11:30\n",
       "                  ...         \n",
       "4312472    2013-01-25 12:55:09\n",
       "4312473    2013-01-25 12:55:10\n",
       "4312474    2013-01-25 12:55:10\n",
       "4312475    2013-01-25 12:55:10\n",
       "4312476    2013-01-25 12:55:10\n",
       "Name: date, Length: 4312477, dtype: object>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data['date'].describe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4312196"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data = df_data.loc[df_data.date.str.len()==19]\n",
    "len(df_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data['datetime'] = df_data['date'].apply(lambda x: pd.Period(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Series.describe of 0          2009-01-12 17:11:30\n",
       "1          2009-01-12 17:11:30\n",
       "2          2009-01-12 17:11:30\n",
       "3          2009-01-12 17:11:30\n",
       "4          2009-01-12 17:11:30\n",
       "                  ...         \n",
       "4312472    2013-01-25 12:55:09\n",
       "4312473    2013-01-25 12:55:10\n",
       "4312474    2013-01-25 12:55:10\n",
       "4312475    2013-01-25 12:55:10\n",
       "4312476    2013-01-25 12:55:10\n",
       "Name: datetime, Length: 4312196, dtype: period[S]>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data['datetime'].describe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data['year'] = df_data['datetime'].apply(lambda x: x.year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data['dayofyear'] = df_data['datetime'].apply(lambda x: x.dayofyear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data['weekofyear'] = df_data['datetime'].apply(lambda x: x.weekofyear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data['week'] = df_data['datetime'].apply(lambda x: pd.Period(x, freq='W'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count                   4312196\n",
       "unique                      834\n",
       "top       2011-05-30/2011-06-05\n",
       "freq                      69047\n",
       "Name: week, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data['week'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_each_week(week, weekly_df_dict, weekint, to_path):\n",
    "\tweekly_df = weekly_df_dict[week]\n",
    "\tweekly_df = weekly_df[weekly_df['dealised_author_full_name'].notna()]\n",
    "\tif weekly_df.empty: \n",
    "\t\treturn\n",
    "\tweekstr = str(weekint).zfill(3)\n",
    "\tfile_path = to_path + '{}__{}.csv'.format(project, weekstr)\n",
    "\tweekly_df.to_csv(file_path, index=False)\n",
    "\tgc.collect()\n",
    "\treturn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('reading commits...')\n",
    "df_data = pd.read_csv(lk_path+'commits_final.csv')\n",
    "df_data = df_data.loc[df_data.date.str.len()==19]\n",
    "df_data['week'] = df_data['date'].apply(lambda x: pd.Period(x, freq='W-MON'))\n",
    "print('grouping by project...')\n",
    "df = dict(tuple(df_data.groupby(df_data['project_name'])))\n",
    "to_path = './weekly_data/commits/'\n",
    "if not os.path.exists(to_path):\n",
    "\tos.makedirs(to_path)\n",
    "\n",
    "\n",
    "print('grouping by period...')\n",
    "for project in tqdm(df):\n",
    "\tweekly_df_dict_data = dict(tuple(df[project].groupby(df[project]['week'])))\n",
    "\tlistkeys = list(weekly_df_dict.keys())\n",
    "\tlistkeys.sort()\n",
    "\tp_map(partial(save_each_week, weekly_df_dict= weekly_df_dict, to_path=to_path), listkeys, range(len(listkeys)), num_cpus = 4)\n",
    "\tgc.collect()\n",
    "print('Commits Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Period('2006-06-06/2006-06-12', 'W-MON'), Period('2006-06-13/2006-06-19', 'W-MON'), Period('2006-06-20/2006-06-26', 'W-MON'), Period('2006-06-27/2006-07-03', 'W-MON'), Period('2006-07-04/2006-07-10', 'W-MON'), Period('2006-07-11/2006-07-17', 'W-MON'), Period('2006-07-18/2006-07-24', 'W-MON'), Period('2006-07-25/2006-07-31', 'W-MON'), Period('2006-08-01/2006-08-07', 'W-MON'), Period('2006-08-08/2006-08-14', 'W-MON'), Period('2006-08-15/2006-08-21', 'W-MON'), Period('2006-08-22/2006-08-28', 'W-MON'), Period('2006-08-29/2006-09-04', 'W-MON'), Period('2006-09-05/2006-09-11', 'W-MON'), Period('2006-09-12/2006-09-18', 'W-MON'), Period('2006-09-19/2006-09-25', 'W-MON'), Period('2006-09-26/2006-10-02', 'W-MON'), Period('2006-10-03/2006-10-09', 'W-MON'), Period('2006-10-10/2006-10-16', 'W-MON'), Period('2006-10-17/2006-10-23', 'W-MON'), Period('2006-10-24/2006-10-30', 'W-MON'), Period('2006-10-31/2006-11-06', 'W-MON'), Period('2006-11-07/2006-11-13', 'W-MON'), Period('2006-11-14/2006-11-20', 'W-MON'), Period('2006-11-21/2006-11-27', 'W-MON'), Period('2006-11-28/2006-12-04', 'W-MON'), Period('2006-12-05/2006-12-11', 'W-MON'), Period('2006-12-12/2006-12-18', 'W-MON'), Period('2006-12-19/2006-12-25', 'W-MON'), Period('2006-12-26/2007-01-01', 'W-MON'), Period('2007-01-02/2007-01-08', 'W-MON'), Period('2007-01-09/2007-01-15', 'W-MON'), Period('2007-01-30/2007-02-05', 'W-MON'), Period('2007-02-06/2007-02-12', 'W-MON'), Period('2007-02-13/2007-02-19', 'W-MON'), Period('2007-02-20/2007-02-26', 'W-MON'), Period('2007-03-06/2007-03-12', 'W-MON'), Period('2007-03-13/2007-03-19', 'W-MON'), Period('2007-03-20/2007-03-26', 'W-MON'), Period('2007-03-27/2007-04-02', 'W-MON'), Period('2007-04-03/2007-04-09', 'W-MON'), Period('2007-04-10/2007-04-16', 'W-MON'), Period('2007-04-17/2007-04-23', 'W-MON'), Period('2007-04-24/2007-04-30', 'W-MON'), Period('2007-05-15/2007-05-21', 'W-MON'), Period('2007-05-22/2007-05-28', 'W-MON'), Period('2007-05-29/2007-06-04', 'W-MON'), Period('2007-06-05/2007-06-11', 'W-MON'), Period('2007-06-12/2007-06-18', 'W-MON'), Period('2007-06-19/2007-06-25', 'W-MON'), Period('2007-06-26/2007-07-02', 'W-MON'), Period('2007-07-03/2007-07-09', 'W-MON'), Period('2007-07-10/2007-07-16', 'W-MON'), Period('2007-07-17/2007-07-23', 'W-MON'), Period('2007-07-24/2007-07-30', 'W-MON'), Period('2007-07-31/2007-08-06', 'W-MON'), Period('2007-08-07/2007-08-13', 'W-MON'), Period('2007-08-14/2007-08-20', 'W-MON'), Period('2007-08-21/2007-08-27', 'W-MON'), Period('2007-08-28/2007-09-03', 'W-MON'), Period('2007-09-04/2007-09-10', 'W-MON'), Period('2007-09-11/2007-09-17', 'W-MON'), Period('2007-09-18/2007-09-24', 'W-MON'), Period('2007-09-25/2007-10-01', 'W-MON'), Period('2007-10-02/2007-10-08', 'W-MON'), Period('2007-10-09/2007-10-15', 'W-MON'), Period('2007-10-16/2007-10-22', 'W-MON'), Period('2007-10-23/2007-10-29', 'W-MON'), Period('2007-10-30/2007-11-05', 'W-MON'), Period('2007-11-06/2007-11-12', 'W-MON'), Period('2007-11-13/2007-11-19', 'W-MON'), Period('2007-11-20/2007-11-26', 'W-MON'), Period('2007-11-27/2007-12-03', 'W-MON'), Period('2007-12-04/2007-12-10', 'W-MON'), Period('2007-12-11/2007-12-17', 'W-MON'), Period('2007-12-18/2007-12-24', 'W-MON'), Period('2008-01-01/2008-01-07', 'W-MON'), Period('2008-01-08/2008-01-14', 'W-MON'), Period('2008-01-15/2008-01-21', 'W-MON'), Period('2008-01-22/2008-01-28', 'W-MON'), Period('2008-01-29/2008-02-04', 'W-MON'), Period('2008-02-05/2008-02-11', 'W-MON'), Period('2008-02-12/2008-02-18', 'W-MON'), Period('2008-02-19/2008-02-25', 'W-MON'), Period('2008-02-26/2008-03-03', 'W-MON'), Period('2008-03-04/2008-03-10', 'W-MON'), Period('2008-03-11/2008-03-17', 'W-MON'), Period('2008-03-18/2008-03-24', 'W-MON'), Period('2008-03-25/2008-03-31', 'W-MON'), Period('2008-04-01/2008-04-07', 'W-MON'), Period('2008-04-08/2008-04-14', 'W-MON'), Period('2008-04-15/2008-04-21', 'W-MON'), Period('2008-04-29/2008-05-05', 'W-MON'), Period('2008-05-06/2008-05-12', 'W-MON'), Period('2008-05-13/2008-05-19', 'W-MON'), Period('2008-05-27/2008-06-02', 'W-MON'), Period('2008-06-03/2008-06-09', 'W-MON'), Period('2008-06-17/2008-06-23', 'W-MON'), Period('2008-06-24/2008-06-30', 'W-MON'), Period('2008-07-01/2008-07-07', 'W-MON'), Period('2008-07-08/2008-07-14', 'W-MON'), Period('2008-07-15/2008-07-21', 'W-MON'), Period('2008-07-22/2008-07-28', 'W-MON'), Period('2008-07-29/2008-08-04', 'W-MON'), Period('2008-08-05/2008-08-11', 'W-MON'), Period('2008-08-12/2008-08-18', 'W-MON'), Period('2008-08-19/2008-08-25', 'W-MON'), Period('2008-09-16/2008-09-22', 'W-MON'), Period('2008-09-30/2008-10-06', 'W-MON'), Period('2008-10-14/2008-10-20', 'W-MON')]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "110"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listkeys = list(weekly_df_dict.keys())\n",
    "listkeys.sort()\n",
    "print(listkeys)\n",
    "len(listkeys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "107"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(weekly_df_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------- processing commits ---------------------- \n",
    "print('reading commits...')\n",
    "df_data = pd.read_csv(lk_path+'commits_final.csv')\n",
    "df_data = df_data.loc[df_data.date.str.len()==19]\n",
    "df_data['week'] = df_data['date'].apply(lambda x: pd.Period(x, freq='W-MON'))\n",
    "print('grouping by project...')\n",
    "df = dict(tuple(df_data.groupby(df_data['project_name'])))\n",
    "to_path = './weekly_data/commits/'\n",
    "if not os.path.exists(to_path):\n",
    "\tos.makedirs(to_path)\n",
    "\n",
    "\n",
    "print('grouping by period...')\n",
    "for project in tqdm(df):\n",
    "\tweekly_df_dict = dict(tuple(df[project].groupby(df[project]['week'])))\n",
    "\tweekint = 0\n",
    "\tfor week in weekly_df_dict:\n",
    "\t\tweekly_df = weekly_df_dict[week]\n",
    "\t\tweekly_df = weekly_df[weekly_df['dealised_author_full_name'].notna()]\n",
    "\t\tweekint+=1\n",
    "\t\tif weekly_df.empty: continue\n",
    "\t\tweekstr = str(weekint).zfill(3)\n",
    "\t\tfile_path = to_path + '{}__{}.csv'.format(project, weekstr)\n",
    "\t\tweekly_df.to_csv(file_path, index=False)\n",
    "print('Commits Done.')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------- processing emails ---------------------- \n",
    "print('reading emails...')\n",
    "df_data = pd.read_csv(lk_path+'emails_final.csv')\n",
    "print('grouping by project...')\n",
    "df_data = df_data.loc[df_data.date.str.len()==19]\n",
    "df_data['week'] = df_data['date'].apply(lambda x: pd.Period(x, freq='W-MON'))\n",
    "print('grouping by project...')\n",
    "df = dict(tuple(df_data.groupby(df_data['project_name'])))\n",
    "to_path = './weekly_data/emails/'\n",
    "if not os.path.exists(to_path):\n",
    "\tos.makedirs(to_path)\n",
    "\n",
    "print('grouping by period...')\n",
    "for project in tqdm(df):\n",
    "\tweekly_df_dict = dict(tuple(df[project].groupby(df[project]['week'])))\n",
    "\tweekint = 0\n",
    "\tfor week in weekly_df_dict:\n",
    "\t\tweekly_df = weekly_df_dict[week]\n",
    "\t\tweekly_df = weekly_df[weekly_df['dealised_author_full_name'].notna()]\n",
    "\t\tweekint+=1\n",
    "\t\tif weekly_df.empty: continue\n",
    "\t\tweekstr = str(weekint).zfill(3)\n",
    "\t\tfile_path = to_path + '{}__{}.csv'.format(project, weekstr)\n",
    "\t\tweekly_df.to_csv(file_path, index=False)\n",
    "print('Emails Done.')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0c125d54415bf97f751e5832101874a2f084e84c850663dda323e1a70b27f8b7"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('3.8.10': pyenv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
